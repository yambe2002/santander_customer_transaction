{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yuzo/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv')\n",
    "#train_df = pd.read_csv('input/train_min.csv')\n",
    "test_df = pd.read_csv('input/test.csv')\n",
    "\n",
    "do_lda = False\n",
    "\n",
    "fix_data_skew = True\n",
    "\n",
    "if fix_data_skew:\n",
    "    trues = train_df.loc[train_df['target'] == 1]\n",
    "    falses = train_df.loc[train_df['target'] != 1].sample(frac=1)[:len(trues)]\n",
    "    train_df = pd.concat([trues, falses], ignore_index=True).sample(frac=1)\n",
    "else:\n",
    "    train_df = train_df\n",
    "    \n",
    "train_df.head()\n",
    "\n",
    "X_test = test_df.drop('ID_code',axis=1)\n",
    "X = train_df.drop(['ID_code','target'],axis=1)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_lda:    \n",
    "    lda = LDA(solver='svd', n_components=5, store_covariance=True)\n",
    "    X_lda = pd.DataFrame(lda.fit_transform(X, y))\n",
    "    X_test_lda = pd.DataFrame(lda.transform(X_test))\n",
    "    X[\"lda\"] = X_lda\n",
    "    X_test[\"lda\"] = X_test_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# cv: 0.89951\n",
    "params = {\n",
    "         'num_leaves': 8,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4 \n",
    "        }\n",
    "'''\n",
    "\n",
    "\n",
    "# 1st round looks good: cv 0.900043\n",
    "# lb: 0.899 with n_splits=10\n",
    "# try larger max_bin?\n",
    "params = {\n",
    "         'num_leaves': 8,\n",
    "         'min_data_in_leaf': 1000,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4,\n",
    "         'max_bin': 511,\n",
    "        }\n",
    "\n",
    "# now trying\n",
    "params = {\n",
    "         'min_data_in_leaf': 1000,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 1,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4,\n",
    "         'max_bin': 31,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Tue Mar  5 19:32:49 2019\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[300]\ttraining's auc: 0.728162\tvalid_1's auc: 0.728861\n",
      "[600]\ttraining's auc: 0.773106\tvalid_1's auc: 0.76972\n",
      "[900]\ttraining's auc: 0.796841\tvalid_1's auc: 0.791026\n",
      "[1200]\ttraining's auc: 0.811731\tvalid_1's auc: 0.804983\n",
      "[1500]\ttraining's auc: 0.821186\tvalid_1's auc: 0.812921\n",
      "[1800]\ttraining's auc: 0.830616\tvalid_1's auc: 0.822394\n",
      "[2100]\ttraining's auc: 0.837608\tvalid_1's auc: 0.829168\n",
      "[2400]\ttraining's auc: 0.843862\tvalid_1's auc: 0.835526\n",
      "[2700]\ttraining's auc: 0.849008\tvalid_1's auc: 0.840536\n",
      "[3000]\ttraining's auc: 0.853836\tvalid_1's auc: 0.845251\n",
      "[3300]\ttraining's auc: 0.857645\tvalid_1's auc: 0.848726\n",
      "[3600]\ttraining's auc: 0.861225\tvalid_1's auc: 0.851973\n",
      "[3900]\ttraining's auc: 0.864814\tvalid_1's auc: 0.855928\n",
      "[4200]\ttraining's auc: 0.867295\tvalid_1's auc: 0.858048\n",
      "[4500]\ttraining's auc: 0.869947\tvalid_1's auc: 0.860456\n",
      "[4800]\ttraining's auc: 0.872677\tvalid_1's auc: 0.863361\n",
      "[5100]\ttraining's auc: 0.874716\tvalid_1's auc: 0.865178\n",
      "[5400]\ttraining's auc: 0.876652\tvalid_1's auc: 0.866784\n",
      "[5700]\ttraining's auc: 0.878341\tvalid_1's auc: 0.8684\n",
      "[6000]\ttraining's auc: 0.87978\tvalid_1's auc: 0.869857\n",
      "[6300]\ttraining's auc: 0.881375\tvalid_1's auc: 0.87103\n",
      "[6600]\ttraining's auc: 0.882822\tvalid_1's auc: 0.872226\n",
      "[6900]\ttraining's auc: 0.884102\tvalid_1's auc: 0.873189\n",
      "[7200]\ttraining's auc: 0.885316\tvalid_1's auc: 0.874197\n",
      "[7500]\ttraining's auc: 0.886559\tvalid_1's auc: 0.874928\n",
      "[7800]\ttraining's auc: 0.887623\tvalid_1's auc: 0.875772\n",
      "[8100]\ttraining's auc: 0.888722\tvalid_1's auc: 0.876797\n",
      "[8400]\ttraining's auc: 0.889583\tvalid_1's auc: 0.877646\n"
     ]
    }
   ],
   "source": [
    "prediction = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data,num_boost_round=2000000,\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 1000)\n",
    "    \n",
    "    prediction += model.predict(X_test, num_iteration=model.best_iteration)/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "sub[\"target\"] = prediction\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
