{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_features = True\n",
    "\n",
    "train_df = pd.read_csv('input/train' + ('_more_features' if more_features else '') + '.csv')\n",
    "test_df = pd.read_csv('input/test'  + ('_more_features' if more_features else '') + '.csv')\n",
    "\n",
    "do_lda = False\n",
    "\n",
    "fix_data_skew = False\n",
    "\n",
    "if fix_data_skew:\n",
    "    trues = train_df.loc[train_df['target'] == 1]\n",
    "    falses = train_df.loc[train_df['target'] != 1].sample(frac=1)[:len(trues)]\n",
    "    train_df = pd.concat([trues, falses], ignore_index=True).sample(frac=1)\n",
    "else:\n",
    "    train_df = train_df\n",
    "    \n",
    "X_test = test_df.drop('ID_code',axis=1)\n",
    "X = train_df.drop(['ID_code','target'],axis=1)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_lda:    \n",
    "    lda = LDA(solver='svd', n_components=5, store_covariance=True)\n",
    "    X_lda = pd.DataFrame(lda.fit_transform(X, y))\n",
    "    X_test_lda = pd.DataFrame(lda.transform(X_test))\n",
    "    X[\"lda\"] = X_lda\n",
    "    X_test[\"lda\"] = X_test_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_bottomhalf, _, y_bottomhalf = train_test_split(X, y, test_size=0.5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>lg</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>gnb</th>\n",
       "      <th>qda</th>\n",
       "      <th>models_mean</th>\n",
       "      <th>models_min</th>\n",
       "      <th>models_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188807</th>\n",
       "      <td>13.9450</td>\n",
       "      <td>2.3554</td>\n",
       "      <td>14.3314</td>\n",
       "      <td>4.1451</td>\n",
       "      <td>11.2540</td>\n",
       "      <td>-1.2150</td>\n",
       "      <td>5.1511</td>\n",
       "      <td>11.9268</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>7.7772</td>\n",
       "      <td>...</td>\n",
       "      <td>16.1058</td>\n",
       "      <td>9.0279</td>\n",
       "      <td>0.080034</td>\n",
       "      <td>0.088045</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.053350</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.080034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199122</th>\n",
       "      <td>13.9229</td>\n",
       "      <td>4.5074</td>\n",
       "      <td>12.2940</td>\n",
       "      <td>4.2445</td>\n",
       "      <td>12.4770</td>\n",
       "      <td>-1.9773</td>\n",
       "      <td>6.7787</td>\n",
       "      <td>13.7641</td>\n",
       "      <td>-1.8372</td>\n",
       "      <td>8.5231</td>\n",
       "      <td>...</td>\n",
       "      <td>16.8185</td>\n",
       "      <td>1.5988</td>\n",
       "      <td>0.038435</td>\n",
       "      <td>0.085816</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.038435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17944</th>\n",
       "      <td>7.4262</td>\n",
       "      <td>-6.5208</td>\n",
       "      <td>14.0846</td>\n",
       "      <td>4.1349</td>\n",
       "      <td>7.9542</td>\n",
       "      <td>-17.4894</td>\n",
       "      <td>4.6857</td>\n",
       "      <td>12.2016</td>\n",
       "      <td>-2.5820</td>\n",
       "      <td>7.1201</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0191</td>\n",
       "      <td>9.7219</td>\n",
       "      <td>0.135709</td>\n",
       "      <td>0.107551</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.034572</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.135709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199504</th>\n",
       "      <td>14.6156</td>\n",
       "      <td>2.0123</td>\n",
       "      <td>10.6881</td>\n",
       "      <td>8.3708</td>\n",
       "      <td>12.5464</td>\n",
       "      <td>-2.9699</td>\n",
       "      <td>5.8589</td>\n",
       "      <td>20.3338</td>\n",
       "      <td>-4.7277</td>\n",
       "      <td>5.8077</td>\n",
       "      <td>...</td>\n",
       "      <td>14.8694</td>\n",
       "      <td>0.3710</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>0.258768</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.925023</td>\n",
       "      <td>0.833709</td>\n",
       "      <td>0.798733</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>0.833709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168703</th>\n",
       "      <td>8.7499</td>\n",
       "      <td>-3.1035</td>\n",
       "      <td>9.5713</td>\n",
       "      <td>6.0757</td>\n",
       "      <td>12.9089</td>\n",
       "      <td>0.5579</td>\n",
       "      <td>5.5508</td>\n",
       "      <td>17.4529</td>\n",
       "      <td>-5.2844</td>\n",
       "      <td>6.3188</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5926</td>\n",
       "      <td>5.9859</td>\n",
       "      <td>0.120143</td>\n",
       "      <td>0.110150</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.112423</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.090754</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.120143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "188807  13.9450  2.3554  14.3314  4.1451  11.2540  -1.2150  5.1511  11.9268   \n",
       "199122  13.9229  4.5074  12.2940  4.2445  12.4770  -1.9773  6.7787  13.7641   \n",
       "17944    7.4262 -6.5208  14.0846  4.1349   7.9542 -17.4894  4.6857  12.2016   \n",
       "199504  14.6156  2.0123  10.6881  8.3708  12.5464  -2.9699  5.8589  20.3338   \n",
       "168703   8.7499 -3.1035   9.5713  6.0757  12.9089   0.5579  5.5508  17.4529   \n",
       "\n",
       "         var_8   var_9     ...      var_198  var_199        lg       mlp  \\\n",
       "188807  0.9658  7.7772     ...      16.1058   9.0279  0.080034  0.088045   \n",
       "199122 -1.8372  8.5231     ...      16.8185   1.5988  0.038435  0.085816   \n",
       "17944  -2.5820  7.1201     ...      17.0191   9.7219  0.135709  0.107551   \n",
       "199504 -4.7277  5.8077     ...      14.8694   0.3710  0.763758  0.258768   \n",
       "168703 -5.2844  6.3188     ...       9.5926   5.9859  0.120143  0.110150   \n",
       "\n",
       "          rf       gnb       qda  models_mean  models_min  models_max  \n",
       "188807  0.06  0.008120  0.026667     0.053350    0.026667    0.080034  \n",
       "199122  0.18  0.028455  0.004738     0.021587    0.004738    0.038435  \n",
       "17944   0.12  0.034572  0.006636     0.071173    0.006636    0.135709  \n",
       "199504  0.22  0.925023  0.833709     0.798733    0.763758    0.833709  \n",
       "168703  0.08  0.112423  0.061366     0.090754    0.061366    0.120143  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bottomhalf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'min_data_in_leaf': 2881,\n",
    "    'max_depth': 0,\n",
    "    'num_leaves': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'bagging_freq': 3,\n",
    "    #'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.3, 0.9),\n",
    "    'feature_fraction': 0.8453828656355421,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha':  1.1173044727720816,\n",
    "    'reg_lambda': 6.9285776442737514,\n",
    "    'random_state': 42,\n",
    "    'verbosity': -1,\n",
    "    'subsample':0.8421287738494433,\n",
    "    'min_child_weight': 36.93038816860224,\n",
    "    'num_threads': 4,\n",
    "    'max_bin': 483\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Mon Mar 18 11:49:36 2019\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.886505\tvalid_1's auc: 0.886111\n",
      "[600]\ttraining's auc: 0.888686\tvalid_1's auc: 0.888369\n",
      "[900]\ttraining's auc: 0.890376\tvalid_1's auc: 0.88953\n",
      "[1200]\ttraining's auc: 0.891735\tvalid_1's auc: 0.890122\n",
      "[1500]\ttraining's auc: 0.892995\tvalid_1's auc: 0.89066\n",
      "[1800]\ttraining's auc: 0.8941\tvalid_1's auc: 0.891077\n",
      "[2100]\ttraining's auc: 0.895101\tvalid_1's auc: 0.891418\n",
      "[2400]\ttraining's auc: 0.896051\tvalid_1's auc: 0.891721\n",
      "[2700]\ttraining's auc: 0.897019\tvalid_1's auc: 0.891938\n",
      "[3000]\ttraining's auc: 0.897888\tvalid_1's auc: 0.892161\n",
      "[3300]\ttraining's auc: 0.898739\tvalid_1's auc: 0.892371\n",
      "[3600]\ttraining's auc: 0.899526\tvalid_1's auc: 0.892583\n",
      "[3900]\ttraining's auc: 0.900284\tvalid_1's auc: 0.892824\n",
      "[4200]\ttraining's auc: 0.90104\tvalid_1's auc: 0.892931\n",
      "[4500]\ttraining's auc: 0.901811\tvalid_1's auc: 0.893059\n",
      "[4800]\ttraining's auc: 0.902515\tvalid_1's auc: 0.893221\n",
      "[5100]\ttraining's auc: 0.903157\tvalid_1's auc: 0.893391\n",
      "[5400]\ttraining's auc: 0.903817\tvalid_1's auc: 0.893465\n",
      "[5700]\ttraining's auc: 0.904471\tvalid_1's auc: 0.893524\n",
      "[6000]\ttraining's auc: 0.90509\tvalid_1's auc: 0.893588\n",
      "[6300]\ttraining's auc: 0.905684\tvalid_1's auc: 0.893702\n",
      "[6600]\ttraining's auc: 0.9063\tvalid_1's auc: 0.893773\n",
      "[6900]\ttraining's auc: 0.90687\tvalid_1's auc: 0.893878\n",
      "[7200]\ttraining's auc: 0.907437\tvalid_1's auc: 0.893934\n",
      "[7500]\ttraining's auc: 0.907994\tvalid_1's auc: 0.894039\n",
      "[7800]\ttraining's auc: 0.908576\tvalid_1's auc: 0.894062\n",
      "[8100]\ttraining's auc: 0.90913\tvalid_1's auc: 0.894146\n",
      "[8400]\ttraining's auc: 0.909664\tvalid_1's auc: 0.894295\n",
      "[8700]\ttraining's auc: 0.91015\tvalid_1's auc: 0.894313\n",
      "[9000]\ttraining's auc: 0.910677\tvalid_1's auc: 0.894363\n",
      "[9300]\ttraining's auc: 0.911218\tvalid_1's auc: 0.894383\n",
      "[9600]\ttraining's auc: 0.911697\tvalid_1's auc: 0.894441\n",
      "[9900]\ttraining's auc: 0.912195\tvalid_1's auc: 0.894462\n",
      "[10200]\ttraining's auc: 0.912651\tvalid_1's auc: 0.894498\n",
      "[10500]\ttraining's auc: 0.913106\tvalid_1's auc: 0.894528\n",
      "[10800]\ttraining's auc: 0.913584\tvalid_1's auc: 0.894494\n",
      "[11100]\ttraining's auc: 0.914062\tvalid_1's auc: 0.894548\n",
      "[11400]\ttraining's auc: 0.914521\tvalid_1's auc: 0.894547\n",
      "[11700]\ttraining's auc: 0.91498\tvalid_1's auc: 0.894541\n",
      "[12000]\ttraining's auc: 0.91544\tvalid_1's auc: 0.894651\n",
      "[12300]\ttraining's auc: 0.915886\tvalid_1's auc: 0.894693\n",
      "[12600]\ttraining's auc: 0.916342\tvalid_1's auc: 0.894754\n",
      "[12900]\ttraining's auc: 0.916765\tvalid_1's auc: 0.894748\n",
      "[13200]\ttraining's auc: 0.917219\tvalid_1's auc: 0.894724\n",
      "Early stopping, best iteration is:\n",
      "[12531]\ttraining's auc: 0.916242\tvalid_1's auc: 0.894776\n",
      "Fold 1 started at Mon Mar 18 11:52:24 2019\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.886155\tvalid_1's auc: 0.887866\n",
      "[600]\ttraining's auc: 0.888366\tvalid_1's auc: 0.88946\n",
      "[900]\ttraining's auc: 0.890115\tvalid_1's auc: 0.890531\n",
      "[1200]\ttraining's auc: 0.89156\tvalid_1's auc: 0.891048\n",
      "[1500]\ttraining's auc: 0.892813\tvalid_1's auc: 0.891436\n",
      "[1800]\ttraining's auc: 0.893962\tvalid_1's auc: 0.891848\n",
      "[2100]\ttraining's auc: 0.895046\tvalid_1's auc: 0.892117\n",
      "[2400]\ttraining's auc: 0.896054\tvalid_1's auc: 0.892287\n",
      "[2700]\ttraining's auc: 0.897008\tvalid_1's auc: 0.892524\n",
      "[3000]\ttraining's auc: 0.897884\tvalid_1's auc: 0.892655\n",
      "[3300]\ttraining's auc: 0.898746\tvalid_1's auc: 0.892865\n",
      "[3600]\ttraining's auc: 0.8995\tvalid_1's auc: 0.892968\n",
      "[3900]\ttraining's auc: 0.900257\tvalid_1's auc: 0.893137\n",
      "[4200]\ttraining's auc: 0.900986\tvalid_1's auc: 0.893223\n",
      "[4500]\ttraining's auc: 0.901725\tvalid_1's auc: 0.893317\n",
      "[4800]\ttraining's auc: 0.902446\tvalid_1's auc: 0.893523\n",
      "[5100]\ttraining's auc: 0.903154\tvalid_1's auc: 0.893706\n",
      "[5400]\ttraining's auc: 0.903817\tvalid_1's auc: 0.893825\n",
      "[5700]\ttraining's auc: 0.904452\tvalid_1's auc: 0.893911\n",
      "[6000]\ttraining's auc: 0.905115\tvalid_1's auc: 0.89407\n",
      "[6300]\ttraining's auc: 0.905724\tvalid_1's auc: 0.894168\n",
      "[6600]\ttraining's auc: 0.906313\tvalid_1's auc: 0.894199\n",
      "[6900]\ttraining's auc: 0.906865\tvalid_1's auc: 0.894316\n",
      "[7200]\ttraining's auc: 0.907476\tvalid_1's auc: 0.894396\n",
      "[7500]\ttraining's auc: 0.908042\tvalid_1's auc: 0.89442\n",
      "[7800]\ttraining's auc: 0.908627\tvalid_1's auc: 0.894451\n",
      "[8100]\ttraining's auc: 0.909155\tvalid_1's auc: 0.894561\n",
      "[8400]\ttraining's auc: 0.90964\tvalid_1's auc: 0.894618\n",
      "[8700]\ttraining's auc: 0.910171\tvalid_1's auc: 0.894725\n",
      "[9000]\ttraining's auc: 0.910714\tvalid_1's auc: 0.894755\n",
      "[9300]\ttraining's auc: 0.911235\tvalid_1's auc: 0.89481\n",
      "[9600]\ttraining's auc: 0.911686\tvalid_1's auc: 0.894826\n",
      "[9900]\ttraining's auc: 0.912157\tvalid_1's auc: 0.894773\n",
      "[10200]\ttraining's auc: 0.912645\tvalid_1's auc: 0.894786\n",
      "Early stopping, best iteration is:\n",
      "[9630]\ttraining's auc: 0.911737\tvalid_1's auc: 0.894845\n",
      "Fold 2 started at Mon Mar 18 11:54:29 2019\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.88521\tvalid_1's auc: 0.891594\n",
      "[600]\ttraining's auc: 0.887441\tvalid_1's auc: 0.89329\n",
      "[900]\ttraining's auc: 0.889221\tvalid_1's auc: 0.894167\n",
      "[1200]\ttraining's auc: 0.890624\tvalid_1's auc: 0.894802\n",
      "[1500]\ttraining's auc: 0.891841\tvalid_1's auc: 0.895318\n",
      "[1800]\ttraining's auc: 0.892959\tvalid_1's auc: 0.895785\n",
      "[2100]\ttraining's auc: 0.893994\tvalid_1's auc: 0.896147\n",
      "[2400]\ttraining's auc: 0.89497\tvalid_1's auc: 0.896438\n",
      "[2700]\ttraining's auc: 0.895879\tvalid_1's auc: 0.896696\n",
      "[3000]\ttraining's auc: 0.896707\tvalid_1's auc: 0.896945\n",
      "[3300]\ttraining's auc: 0.897517\tvalid_1's auc: 0.897133\n",
      "[3600]\ttraining's auc: 0.898307\tvalid_1's auc: 0.897339\n",
      "[3900]\ttraining's auc: 0.89912\tvalid_1's auc: 0.897457\n",
      "[4200]\ttraining's auc: 0.89986\tvalid_1's auc: 0.897643\n",
      "[4500]\ttraining's auc: 0.900555\tvalid_1's auc: 0.897794\n",
      "[4800]\ttraining's auc: 0.90126\tvalid_1's auc: 0.898015\n",
      "[5100]\ttraining's auc: 0.901897\tvalid_1's auc: 0.898155\n",
      "[5400]\ttraining's auc: 0.902551\tvalid_1's auc: 0.898321\n",
      "[5700]\ttraining's auc: 0.903184\tvalid_1's auc: 0.898447\n",
      "[6000]\ttraining's auc: 0.903779\tvalid_1's auc: 0.898573\n",
      "[6300]\ttraining's auc: 0.904374\tvalid_1's auc: 0.898687\n",
      "[6600]\ttraining's auc: 0.904955\tvalid_1's auc: 0.898796\n",
      "[6900]\ttraining's auc: 0.905562\tvalid_1's auc: 0.898915\n",
      "[7200]\ttraining's auc: 0.906165\tvalid_1's auc: 0.899012\n",
      "[7500]\ttraining's auc: 0.906721\tvalid_1's auc: 0.899085\n",
      "[7800]\ttraining's auc: 0.907284\tvalid_1's auc: 0.899203\n",
      "[8100]\ttraining's auc: 0.907851\tvalid_1's auc: 0.899258\n",
      "[8400]\ttraining's auc: 0.908354\tvalid_1's auc: 0.899365\n",
      "[8700]\ttraining's auc: 0.908863\tvalid_1's auc: 0.899474\n",
      "[9000]\ttraining's auc: 0.909371\tvalid_1's auc: 0.899561\n",
      "[9300]\ttraining's auc: 0.909814\tvalid_1's auc: 0.899641\n",
      "[9600]\ttraining's auc: 0.910318\tvalid_1's auc: 0.899651\n",
      "[9900]\ttraining's auc: 0.91081\tvalid_1's auc: 0.899681\n",
      "[10200]\ttraining's auc: 0.911305\tvalid_1's auc: 0.899767\n",
      "[10500]\ttraining's auc: 0.911765\tvalid_1's auc: 0.899763\n",
      "[10800]\ttraining's auc: 0.912207\tvalid_1's auc: 0.899855\n",
      "[11100]\ttraining's auc: 0.912689\tvalid_1's auc: 0.899869\n",
      "[11400]\ttraining's auc: 0.913167\tvalid_1's auc: 0.899925\n",
      "[11700]\ttraining's auc: 0.91365\tvalid_1's auc: 0.899941\n",
      "[12000]\ttraining's auc: 0.914104\tvalid_1's auc: 0.900025\n",
      "[12300]\ttraining's auc: 0.91454\tvalid_1's auc: 0.900003\n",
      "[12600]\ttraining's auc: 0.914971\tvalid_1's auc: 0.900014\n",
      "[12900]\ttraining's auc: 0.915413\tvalid_1's auc: 0.900029\n",
      "[13200]\ttraining's auc: 0.91585\tvalid_1's auc: 0.900048\n",
      "[13500]\ttraining's auc: 0.916249\tvalid_1's auc: 0.900099\n",
      "[13800]\ttraining's auc: 0.916662\tvalid_1's auc: 0.900134\n",
      "[14100]\ttraining's auc: 0.91709\tvalid_1's auc: 0.900151\n",
      "[14400]\ttraining's auc: 0.917496\tvalid_1's auc: 0.900192\n",
      "[14700]\ttraining's auc: 0.917898\tvalid_1's auc: 0.900253\n",
      "[15000]\ttraining's auc: 0.9183\tvalid_1's auc: 0.900241\n",
      "[15300]\ttraining's auc: 0.918737\tvalid_1's auc: 0.900275\n",
      "[15600]\ttraining's auc: 0.919138\tvalid_1's auc: 0.900216\n",
      "[15900]\ttraining's auc: 0.91954\tvalid_1's auc: 0.900213\n",
      "Early stopping, best iteration is:\n",
      "[15255]\ttraining's auc: 0.918674\tvalid_1's auc: 0.900285\n",
      "Fold 3 started at Mon Mar 18 11:57:44 2019\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.888623\tvalid_1's auc: 0.877797\n",
      "[600]\ttraining's auc: 0.890893\tvalid_1's auc: 0.879305\n",
      "[900]\ttraining's auc: 0.892644\tvalid_1's auc: 0.880088\n",
      "[1200]\ttraining's auc: 0.894053\tvalid_1's auc: 0.880686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's auc: 0.895279\tvalid_1's auc: 0.881275\n",
      "[1800]\ttraining's auc: 0.896361\tvalid_1's auc: 0.881728\n",
      "[2100]\ttraining's auc: 0.897403\tvalid_1's auc: 0.88216\n",
      "[2400]\ttraining's auc: 0.898355\tvalid_1's auc: 0.88246\n",
      "[2700]\ttraining's auc: 0.899275\tvalid_1's auc: 0.882712\n",
      "[3000]\ttraining's auc: 0.90013\tvalid_1's auc: 0.882907\n",
      "[3300]\ttraining's auc: 0.90094\tvalid_1's auc: 0.883133\n",
      "[3600]\ttraining's auc: 0.901722\tvalid_1's auc: 0.883276\n",
      "[3900]\ttraining's auc: 0.902471\tvalid_1's auc: 0.883511\n",
      "[4200]\ttraining's auc: 0.903205\tvalid_1's auc: 0.883725\n",
      "[4500]\ttraining's auc: 0.903882\tvalid_1's auc: 0.883866\n",
      "[4800]\ttraining's auc: 0.904555\tvalid_1's auc: 0.884081\n",
      "[5100]\ttraining's auc: 0.905243\tvalid_1's auc: 0.884209\n",
      "[5400]\ttraining's auc: 0.905877\tvalid_1's auc: 0.884386\n",
      "[5700]\ttraining's auc: 0.906476\tvalid_1's auc: 0.884578\n",
      "[6000]\ttraining's auc: 0.907073\tvalid_1's auc: 0.884648\n",
      "[6300]\ttraining's auc: 0.907685\tvalid_1's auc: 0.884803\n",
      "[6600]\ttraining's auc: 0.908292\tvalid_1's auc: 0.884928\n",
      "[6900]\ttraining's auc: 0.908838\tvalid_1's auc: 0.884992\n",
      "[7200]\ttraining's auc: 0.909401\tvalid_1's auc: 0.885101\n",
      "[7500]\ttraining's auc: 0.909929\tvalid_1's auc: 0.885258\n",
      "[7800]\ttraining's auc: 0.91048\tvalid_1's auc: 0.885365\n",
      "[8100]\ttraining's auc: 0.910997\tvalid_1's auc: 0.885476\n",
      "[8400]\ttraining's auc: 0.911512\tvalid_1's auc: 0.885612\n",
      "[8700]\ttraining's auc: 0.912008\tvalid_1's auc: 0.885706\n",
      "[9000]\ttraining's auc: 0.912525\tvalid_1's auc: 0.885833\n",
      "[9300]\ttraining's auc: 0.913045\tvalid_1's auc: 0.8859\n",
      "[9600]\ttraining's auc: 0.913501\tvalid_1's auc: 0.88605\n",
      "[9900]\ttraining's auc: 0.914002\tvalid_1's auc: 0.886187\n",
      "[10200]\ttraining's auc: 0.914448\tvalid_1's auc: 0.886258\n",
      "[10500]\ttraining's auc: 0.914942\tvalid_1's auc: 0.886298\n",
      "[10800]\ttraining's auc: 0.915382\tvalid_1's auc: 0.886377\n",
      "[11100]\ttraining's auc: 0.915836\tvalid_1's auc: 0.886493\n",
      "[11400]\ttraining's auc: 0.916326\tvalid_1's auc: 0.886544\n",
      "[11700]\ttraining's auc: 0.916773\tvalid_1's auc: 0.886647\n",
      "[12000]\ttraining's auc: 0.917197\tvalid_1's auc: 0.886687\n",
      "[12300]\ttraining's auc: 0.91765\tvalid_1's auc: 0.886737\n",
      "[12600]\ttraining's auc: 0.918083\tvalid_1's auc: 0.886781\n",
      "[12900]\ttraining's auc: 0.91849\tvalid_1's auc: 0.886847\n",
      "[13200]\ttraining's auc: 0.918872\tvalid_1's auc: 0.886962\n",
      "[13500]\ttraining's auc: 0.919277\tvalid_1's auc: 0.886982\n",
      "[13800]\ttraining's auc: 0.919692\tvalid_1's auc: 0.887066\n",
      "[14100]\ttraining's auc: 0.920078\tvalid_1's auc: 0.887134\n",
      "[14400]\ttraining's auc: 0.920508\tvalid_1's auc: 0.887174\n",
      "[14700]\ttraining's auc: 0.920902\tvalid_1's auc: 0.887229\n",
      "[15000]\ttraining's auc: 0.92131\tvalid_1's auc: 0.887301\n",
      "[15300]\ttraining's auc: 0.921681\tvalid_1's auc: 0.887316\n",
      "[15600]\ttraining's auc: 0.922093\tvalid_1's auc: 0.887303\n",
      "[15900]\ttraining's auc: 0.922489\tvalid_1's auc: 0.887379\n",
      "[16200]\ttraining's auc: 0.922868\tvalid_1's auc: 0.887375\n",
      "[16500]\ttraining's auc: 0.92323\tvalid_1's auc: 0.887384\n",
      "[16800]\ttraining's auc: 0.923614\tvalid_1's auc: 0.887391\n",
      "[17100]\ttraining's auc: 0.923968\tvalid_1's auc: 0.8874\n",
      "[17400]\ttraining's auc: 0.924366\tvalid_1's auc: 0.887372\n",
      "[17700]\ttraining's auc: 0.924726\tvalid_1's auc: 0.887434\n",
      "[18000]\ttraining's auc: 0.92508\tvalid_1's auc: 0.887502\n",
      "[18300]\ttraining's auc: 0.925437\tvalid_1's auc: 0.887485\n",
      "[18600]\ttraining's auc: 0.925794\tvalid_1's auc: 0.887533\n",
      "[18900]\ttraining's auc: 0.926137\tvalid_1's auc: 0.887511\n",
      "[19200]\ttraining's auc: 0.926469\tvalid_1's auc: 0.887582\n",
      "[19500]\ttraining's auc: 0.926836\tvalid_1's auc: 0.887581\n",
      "[19800]\ttraining's auc: 0.927183\tvalid_1's auc: 0.887552\n",
      "[20100]\ttraining's auc: 0.927534\tvalid_1's auc: 0.887638\n",
      "[20400]\ttraining's auc: 0.927899\tvalid_1's auc: 0.887702\n",
      "[20700]\ttraining's auc: 0.928223\tvalid_1's auc: 0.887689\n",
      "[21000]\ttraining's auc: 0.928594\tvalid_1's auc: 0.887736\n",
      "[21300]\ttraining's auc: 0.928914\tvalid_1's auc: 0.887742\n",
      "[21600]\ttraining's auc: 0.929244\tvalid_1's auc: 0.887748\n",
      "[21900]\ttraining's auc: 0.929602\tvalid_1's auc: 0.88773\n",
      "[22200]\ttraining's auc: 0.929903\tvalid_1's auc: 0.887763\n",
      "[22500]\ttraining's auc: 0.930212\tvalid_1's auc: 0.887759\n",
      "[22800]\ttraining's auc: 0.930532\tvalid_1's auc: 0.887785\n",
      "[23100]\ttraining's auc: 0.930864\tvalid_1's auc: 0.88779\n",
      "[23400]\ttraining's auc: 0.931205\tvalid_1's auc: 0.887843\n",
      "[23700]\ttraining's auc: 0.931524\tvalid_1's auc: 0.887856\n",
      "[24000]\ttraining's auc: 0.931846\tvalid_1's auc: 0.887848\n",
      "[24300]\ttraining's auc: 0.932153\tvalid_1's auc: 0.887817\n",
      "Early stopping, best iteration is:\n",
      "[23572]\ttraining's auc: 0.931371\tvalid_1's auc: 0.887875\n",
      "Fold 4 started at Mon Mar 18 12:02:53 2019\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.886929\tvalid_1's auc: 0.884661\n",
      "[600]\ttraining's auc: 0.889136\tvalid_1's auc: 0.886405\n",
      "[900]\ttraining's auc: 0.890764\tvalid_1's auc: 0.887614\n",
      "[1200]\ttraining's auc: 0.892096\tvalid_1's auc: 0.888484\n",
      "[1500]\ttraining's auc: 0.89328\tvalid_1's auc: 0.889106\n",
      "[1800]\ttraining's auc: 0.894353\tvalid_1's auc: 0.889609\n",
      "[2100]\ttraining's auc: 0.895384\tvalid_1's auc: 0.890182\n",
      "[2400]\ttraining's auc: 0.896334\tvalid_1's auc: 0.890601\n",
      "[2700]\ttraining's auc: 0.897236\tvalid_1's auc: 0.890988\n",
      "[3000]\ttraining's auc: 0.898111\tvalid_1's auc: 0.8913\n",
      "[3300]\ttraining's auc: 0.898969\tvalid_1's auc: 0.891598\n",
      "[3600]\ttraining's auc: 0.899743\tvalid_1's auc: 0.89193\n",
      "[3900]\ttraining's auc: 0.900502\tvalid_1's auc: 0.892109\n",
      "[4200]\ttraining's auc: 0.901265\tvalid_1's auc: 0.892319\n",
      "[4500]\ttraining's auc: 0.901954\tvalid_1's auc: 0.892552\n",
      "[4800]\ttraining's auc: 0.902641\tvalid_1's auc: 0.892769\n",
      "[5100]\ttraining's auc: 0.903342\tvalid_1's auc: 0.892958\n",
      "[5400]\ttraining's auc: 0.903978\tvalid_1's auc: 0.893078\n",
      "[5700]\ttraining's auc: 0.90462\tvalid_1's auc: 0.893188\n",
      "[6000]\ttraining's auc: 0.90522\tvalid_1's auc: 0.893339\n",
      "[6300]\ttraining's auc: 0.905826\tvalid_1's auc: 0.893483\n",
      "[6600]\ttraining's auc: 0.906408\tvalid_1's auc: 0.893613\n",
      "[6900]\ttraining's auc: 0.906962\tvalid_1's auc: 0.893704\n",
      "[7200]\ttraining's auc: 0.907539\tvalid_1's auc: 0.893763\n",
      "[7500]\ttraining's auc: 0.908111\tvalid_1's auc: 0.893865\n",
      "[7800]\ttraining's auc: 0.908673\tvalid_1's auc: 0.893944\n",
      "[8100]\ttraining's auc: 0.909202\tvalid_1's auc: 0.894018\n",
      "[8400]\ttraining's auc: 0.909704\tvalid_1's auc: 0.894137\n",
      "[8700]\ttraining's auc: 0.910211\tvalid_1's auc: 0.894216\n",
      "[9000]\ttraining's auc: 0.91071\tvalid_1's auc: 0.89429\n",
      "[9300]\ttraining's auc: 0.911209\tvalid_1's auc: 0.894317\n",
      "[9600]\ttraining's auc: 0.911726\tvalid_1's auc: 0.894336\n",
      "[9900]\ttraining's auc: 0.912176\tvalid_1's auc: 0.894407\n",
      "[10200]\ttraining's auc: 0.912641\tvalid_1's auc: 0.894433\n",
      "[10500]\ttraining's auc: 0.913114\tvalid_1's auc: 0.894488\n",
      "[10800]\ttraining's auc: 0.913585\tvalid_1's auc: 0.894559\n",
      "[11100]\ttraining's auc: 0.914061\tvalid_1's auc: 0.894629\n",
      "[11400]\ttraining's auc: 0.914512\tvalid_1's auc: 0.894768\n",
      "[11700]\ttraining's auc: 0.914973\tvalid_1's auc: 0.894884\n",
      "[12000]\ttraining's auc: 0.915418\tvalid_1's auc: 0.894854\n",
      "[12300]\ttraining's auc: 0.915867\tvalid_1's auc: 0.894858\n",
      "[12600]\ttraining's auc: 0.916315\tvalid_1's auc: 0.894847\n",
      "[12900]\ttraining's auc: 0.916745\tvalid_1's auc: 0.894884\n",
      "Early stopping, best iteration is:\n",
      "[12197]\ttraining's auc: 0.915707\tvalid_1's auc: 0.894901\n",
      "0.8945364695860429\n"
     ]
    }
   ],
   "source": [
    "score = 0.0\n",
    "prediction = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X_bottomhalf,y_bottomhalf)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X_bottomhalf.iloc[train_index], X_bottomhalf.iloc[valid_index]\n",
    "    y_train, y_valid = y_bottomhalf.iloc[train_index], y_bottomhalf.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data,num_boost_round=2000000,\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 800)\n",
    "    \n",
    "    prediction += model.predict(X_test, num_iteration=model.best_iteration)/n_splits\n",
    "    score += model.best_score['valid_1']['auc'] / n_splits\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "sub[\"target\"] = prediction\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
