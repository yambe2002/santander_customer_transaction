{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>train_44958</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1097</td>\n",
       "      <td>-3.6626</td>\n",
       "      <td>12.9916</td>\n",
       "      <td>5.4532</td>\n",
       "      <td>9.1796</td>\n",
       "      <td>-10.4245</td>\n",
       "      <td>3.3715</td>\n",
       "      <td>13.7593</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0756</td>\n",
       "      <td>14.3647</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>2.4267</td>\n",
       "      <td>17.6248</td>\n",
       "      <td>-0.2987</td>\n",
       "      <td>10.4272</td>\n",
       "      <td>8.7023</td>\n",
       "      <td>15.5484</td>\n",
       "      <td>-2.7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19707</th>\n",
       "      <td>train_196453</td>\n",
       "      <td>1</td>\n",
       "      <td>8.3518</td>\n",
       "      <td>-6.5567</td>\n",
       "      <td>14.6280</td>\n",
       "      <td>7.3526</td>\n",
       "      <td>12.1076</td>\n",
       "      <td>-7.3077</td>\n",
       "      <td>4.6128</td>\n",
       "      <td>10.7624</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1633</td>\n",
       "      <td>5.9991</td>\n",
       "      <td>2.7654</td>\n",
       "      <td>-3.5509</td>\n",
       "      <td>16.6949</td>\n",
       "      <td>0.8259</td>\n",
       "      <td>9.9904</td>\n",
       "      <td>8.1459</td>\n",
       "      <td>12.3860</td>\n",
       "      <td>-21.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>train_37314</td>\n",
       "      <td>1</td>\n",
       "      <td>17.7336</td>\n",
       "      <td>2.4519</td>\n",
       "      <td>11.0154</td>\n",
       "      <td>11.1458</td>\n",
       "      <td>10.8296</td>\n",
       "      <td>-14.1031</td>\n",
       "      <td>4.8839</td>\n",
       "      <td>17.7223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>9.5091</td>\n",
       "      <td>0.8411</td>\n",
       "      <td>0.8898</td>\n",
       "      <td>15.6398</td>\n",
       "      <td>1.8360</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>8.3489</td>\n",
       "      <td>14.9042</td>\n",
       "      <td>-12.4719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>train_51011</td>\n",
       "      <td>1</td>\n",
       "      <td>17.6923</td>\n",
       "      <td>-4.7484</td>\n",
       "      <td>8.4909</td>\n",
       "      <td>7.8138</td>\n",
       "      <td>11.0619</td>\n",
       "      <td>13.4346</td>\n",
       "      <td>5.2511</td>\n",
       "      <td>17.1373</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6474</td>\n",
       "      <td>6.8746</td>\n",
       "      <td>-0.0815</td>\n",
       "      <td>7.8560</td>\n",
       "      <td>21.9572</td>\n",
       "      <td>-1.9430</td>\n",
       "      <td>6.1172</td>\n",
       "      <td>7.9742</td>\n",
       "      <td>18.4485</td>\n",
       "      <td>-8.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>train_113002</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0074</td>\n",
       "      <td>4.7071</td>\n",
       "      <td>12.3721</td>\n",
       "      <td>5.3604</td>\n",
       "      <td>11.3085</td>\n",
       "      <td>-11.3558</td>\n",
       "      <td>5.7844</td>\n",
       "      <td>12.6466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8608</td>\n",
       "      <td>5.7127</td>\n",
       "      <td>2.2585</td>\n",
       "      <td>6.7968</td>\n",
       "      <td>22.2517</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.5512</td>\n",
       "      <td>9.5950</td>\n",
       "      <td>15.6518</td>\n",
       "      <td>7.5509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code  target    var_0   var_1    var_2    var_3    var_4  \\\n",
       "4458    train_44958       1   7.1097 -3.6626  12.9916   5.4532   9.1796   \n",
       "19707  train_196453       1   8.3518 -6.5567  14.6280   7.3526  12.1076   \n",
       "3702    train_37314       1  17.7336  2.4519  11.0154  11.1458  10.8296   \n",
       "5067    train_51011       1  17.6923 -4.7484   8.4909   7.8138  11.0619   \n",
       "11323  train_113002       1   9.0074  4.7071  12.3721   5.3604  11.3085   \n",
       "\n",
       "         var_5   var_6    var_7   ...     var_190  var_191  var_192  var_193  \\\n",
       "4458  -10.4245  3.3715  13.7593   ...      6.0756  14.3647   0.9228   2.4267   \n",
       "19707  -7.3077  4.6128  10.7624   ...      4.1633   5.9991   2.7654  -3.5509   \n",
       "3702  -14.1031  4.8839  17.7223   ...      0.5902   9.5091   0.8411   0.8898   \n",
       "5067   13.4346  5.2511  17.1373   ...      2.6474   6.8746  -0.0815   7.8560   \n",
       "11323 -11.3558  5.7844  12.6466   ...     -0.8608   5.7127   2.2585   6.7968   \n",
       "\n",
       "       var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "4458   17.6248  -0.2987  10.4272   8.7023  15.5484  -2.7033  \n",
       "19707  16.6949   0.8259   9.9904   8.1459  12.3860 -21.0266  \n",
       "3702   15.6398   1.8360   0.3746   8.3489  14.9042 -12.4719  \n",
       "5067   21.9572  -1.9430   6.1172   7.9742  18.4485  -8.7427  \n",
       "11323  22.2517   0.8920   0.5512   9.5950  15.6518   7.5509  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/train.csv')\n",
    "# df = pd.read_csv('input/train_min.csv')  # small data\n",
    "\n",
    "fix_data_skew = True\n",
    "\n",
    "if fix_data_skew:\n",
    "    trues = df.loc[df['target'] == 1]\n",
    "    falses = df.loc[df['target'] != 1].sample(frac=1)[:len(trues)]\n",
    "    data = pd.concat([trues, falses], ignore_index=True).sample(frac=1)\n",
    "else:\n",
    "    data = df\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:,2:].values, data.iloc[:,1].values\n",
    "\n",
    "# std scaling\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator': SGDClassifier(alpha=0.3, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=5000,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=1e-07,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)}\n",
      "0.8614224931614438\n"
     ]
    }
   ],
   "source": [
    "#cv: 0.8597059678850029\n",
    "#    0.8584394316060081 (with data skew fix)\n",
    "lg = SGDClassifier(loss='log', max_iter=5000, tol=1e-7, alpha=0.3)\n",
    "\n",
    "#cv: 0.8543658603036868\n",
    "#    0.8466847795424428 (with data skew fix)\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=0.001,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "# cv: 0.83 (with data skew fix)\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "\n",
    "#cv: 0.8883828469044662\n",
    "#    0.8874777137937799 (with data skew fix)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#cv: 0.8608604117713252 (with data skew fix)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "#cv: 0.820027075184469 (with data skew fix)\n",
    "qda = QuadraticDiscriminantAnalysis(tol=1e-12)\n",
    "\n",
    "# cv: 0.8616254422551686 (with data skew fix)\n",
    "ada = AdaBoostClassifier(lg)\n",
    "\n",
    "# cv: 0.8614224931614438 (with data skew fix)\n",
    "bg = BaggingClassifier(lg);\n",
    "\n",
    "cls = bg\n",
    "\n",
    "# try grid-search\n",
    "params = { 'base_estimator': [ None, lg ] }\n",
    "cls = GridSearchCV(estimator=cls, param_grid=params, cv=5, scoring='roc_auc')\n",
    "cls.fit(X_scaled, y)\n",
    "print(cls.best_params_)\n",
    "print(cls.best_score_)\n",
    "\n",
    "# single\n",
    "#cv_scores = cross_val_score(cls, X_scaled, y, cv=5, scoring='roc_auc')\n",
    "#print(cv_scores)\n",
    "#print(np.average(cv_scores))\n",
    "\n",
    "# voting\n",
    "#estimators = [ ('lda', lda), ('gnb', gnb), ('lg', lg), ('mlp', mlp) ]\n",
    "\n",
    "#vc = VotingClassifier(estimators=estimators.copy(), voting='soft')\n",
    "#estimators.append(('vc', vc))\n",
    "\n",
    "#for label, cls in estimators:\n",
    "#   scores = cross_val_score(cls, X_scaled, y, cv=5, scoring='roc_auc')\n",
    "#   print(\"Score: %0.16f (+/- %0.16f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('gnb', GaussianNB(priors=None, var_smoothing=1e-09)), ('lg', SGDClassifier(alpha=0.3, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=5000,\n",
       "       n_iter=None, n...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft', weights=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final output\n",
    "test = pd.read_csv('input/test.csv')\n",
    "test_ids, test_x = test.iloc[:,0], test.iloc[:,1:]\n",
    "\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "test_y = cls.predict_proba(test_x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.645082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.660114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.506549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.620484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.322633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.645082\n",
       "1  test_1  0.660114\n",
       "2  test_2  0.506549\n",
       "3  test_3  0.620484\n",
       "4  test_4  0.322633"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the result\n",
    "sub_ids = pd.DataFrame(test_ids)\n",
    "sub_y = pd.DataFrame(pd.DataFrame(test_y).iloc[:,1])\n",
    "\n",
    "sub = pd.DataFrame(np.hstack((sub_ids, sub_y)))\n",
    "sub.to_csv('output.csv', header=['ID_code', 'target'], index=False)\n",
    "\n",
    "output_check = pd.read_csv('output.csv')\n",
    "output_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
