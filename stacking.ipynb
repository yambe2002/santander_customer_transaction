{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv')\n",
    "# df = pd.read_csv('input/train_min.csv')  # small data\n",
    "test_df = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('ID_code',axis=1)\n",
    "X = train_df.drop(['ID_code','target'],axis=1)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "0  2.1337  8.8100   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "1 -4.4131  5.9739   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "2  1.5233  8.3442   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "3  3.3755  7.4578   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "4  2.9890  7.1437   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "\n",
       "   var_195  var_196  var_197  var_198  var_199  \n",
       "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  5.7470   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  8.0851   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  5.9525   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  8.2450   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  7.6784   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv = np.zeros(len(X))\n",
    "pred = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on lgbm\n",
      "fold: 0\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.763894\tvalid_1's auc: 0.755421\n",
      "[600]\ttraining's auc: 0.803638\tvalid_1's auc: 0.796102\n",
      "[900]\ttraining's auc: 0.824243\tvalid_1's auc: 0.816561\n",
      "[1200]\ttraining's auc: 0.838573\tvalid_1's auc: 0.830135\n",
      "[1500]\ttraining's auc: 0.848948\tvalid_1's auc: 0.839926\n",
      "[1800]\ttraining's auc: 0.856728\tvalid_1's auc: 0.84737\n",
      "[2100]\ttraining's auc: 0.86311\tvalid_1's auc: 0.853287\n",
      "[2400]\ttraining's auc: 0.868888\tvalid_1's auc: 0.858499\n",
      "[2700]\ttraining's auc: 0.873314\tvalid_1's auc: 0.862411\n",
      "[3000]\ttraining's auc: 0.877112\tvalid_1's auc: 0.865793\n",
      "[3300]\ttraining's auc: 0.880634\tvalid_1's auc: 0.868908\n",
      "[3600]\ttraining's auc: 0.883577\tvalid_1's auc: 0.871514\n",
      "[3900]\ttraining's auc: 0.886398\tvalid_1's auc: 0.873991\n",
      "[4200]\ttraining's auc: 0.888777\tvalid_1's auc: 0.876039\n",
      "[4500]\ttraining's auc: 0.890779\tvalid_1's auc: 0.877823\n",
      "[4800]\ttraining's auc: 0.892801\tvalid_1's auc: 0.879531\n",
      "[5100]\ttraining's auc: 0.894456\tvalid_1's auc: 0.880839\n",
      "[5400]\ttraining's auc: 0.895965\tvalid_1's auc: 0.88225\n",
      "[5700]\ttraining's auc: 0.897502\tvalid_1's auc: 0.883371\n",
      "[6000]\ttraining's auc: 0.898793\tvalid_1's auc: 0.884368\n",
      "[6300]\ttraining's auc: 0.899958\tvalid_1's auc: 0.885383\n",
      "[6600]\ttraining's auc: 0.901091\tvalid_1's auc: 0.886306\n",
      "[6900]\ttraining's auc: 0.902113\tvalid_1's auc: 0.887198\n",
      "[7200]\ttraining's auc: 0.903105\tvalid_1's auc: 0.887972\n",
      "[7500]\ttraining's auc: 0.903963\tvalid_1's auc: 0.888676\n",
      "[7800]\ttraining's auc: 0.904879\tvalid_1's auc: 0.889323\n",
      "[8100]\ttraining's auc: 0.90566\tvalid_1's auc: 0.89\n",
      "[8400]\ttraining's auc: 0.906389\tvalid_1's auc: 0.890511\n",
      "[8700]\ttraining's auc: 0.907074\tvalid_1's auc: 0.891037\n",
      "[9000]\ttraining's auc: 0.907816\tvalid_1's auc: 0.891551\n",
      "[9300]\ttraining's auc: 0.908449\tvalid_1's auc: 0.891994\n",
      "[9600]\ttraining's auc: 0.909063\tvalid_1's auc: 0.892498\n",
      "[9900]\ttraining's auc: 0.909629\tvalid_1's auc: 0.892931\n",
      "[10200]\ttraining's auc: 0.910193\tvalid_1's auc: 0.89329\n",
      "[10500]\ttraining's auc: 0.910689\tvalid_1's auc: 0.893754\n",
      "[10800]\ttraining's auc: 0.911198\tvalid_1's auc: 0.894166\n",
      "[11100]\ttraining's auc: 0.911635\tvalid_1's auc: 0.894537\n",
      "[11400]\ttraining's auc: 0.91206\tvalid_1's auc: 0.89484\n",
      "[11700]\ttraining's auc: 0.912475\tvalid_1's auc: 0.895145\n",
      "[12000]\ttraining's auc: 0.912898\tvalid_1's auc: 0.895431\n",
      "[12300]\ttraining's auc: 0.913248\tvalid_1's auc: 0.895653\n",
      "[12600]\ttraining's auc: 0.913614\tvalid_1's auc: 0.895855\n",
      "[12900]\ttraining's auc: 0.913968\tvalid_1's auc: 0.896105\n",
      "[13200]\ttraining's auc: 0.914322\tvalid_1's auc: 0.89626\n",
      "[13500]\ttraining's auc: 0.914615\tvalid_1's auc: 0.896465\n",
      "[13800]\ttraining's auc: 0.914946\tvalid_1's auc: 0.896741\n",
      "[14100]\ttraining's auc: 0.915258\tvalid_1's auc: 0.896907\n",
      "[14400]\ttraining's auc: 0.915536\tvalid_1's auc: 0.897046\n",
      "[14700]\ttraining's auc: 0.915813\tvalid_1's auc: 0.897184\n",
      "[15000]\ttraining's auc: 0.91607\tvalid_1's auc: 0.897342\n",
      "[15300]\ttraining's auc: 0.916319\tvalid_1's auc: 0.897453\n",
      "[15600]\ttraining's auc: 0.916604\tvalid_1's auc: 0.897635\n",
      "[15900]\ttraining's auc: 0.916842\tvalid_1's auc: 0.897759\n",
      "[16200]\ttraining's auc: 0.917102\tvalid_1's auc: 0.897894\n",
      "[16500]\ttraining's auc: 0.917345\tvalid_1's auc: 0.898055\n",
      "[16800]\ttraining's auc: 0.917581\tvalid_1's auc: 0.898181\n",
      "[17100]\ttraining's auc: 0.917784\tvalid_1's auc: 0.898277\n",
      "[17400]\ttraining's auc: 0.917977\tvalid_1's auc: 0.898398\n",
      "[17700]\ttraining's auc: 0.918186\tvalid_1's auc: 0.898452\n",
      "[18000]\ttraining's auc: 0.918426\tvalid_1's auc: 0.898495\n",
      "[18300]\ttraining's auc: 0.918625\tvalid_1's auc: 0.898573\n",
      "[18600]\ttraining's auc: 0.918838\tvalid_1's auc: 0.898644\n",
      "[18900]\ttraining's auc: 0.919045\tvalid_1's auc: 0.898729\n",
      "[19200]\ttraining's auc: 0.919259\tvalid_1's auc: 0.898773\n",
      "[19500]\ttraining's auc: 0.919455\tvalid_1's auc: 0.898875\n",
      "[19800]\ttraining's auc: 0.919676\tvalid_1's auc: 0.898942\n",
      "[20100]\ttraining's auc: 0.919874\tvalid_1's auc: 0.898983\n",
      "[20400]\ttraining's auc: 0.920064\tvalid_1's auc: 0.899017\n",
      "[20700]\ttraining's auc: 0.920269\tvalid_1's auc: 0.8991\n",
      "[21000]\ttraining's auc: 0.920464\tvalid_1's auc: 0.899127\n",
      "[21300]\ttraining's auc: 0.92065\tvalid_1's auc: 0.899146\n",
      "[21600]\ttraining's auc: 0.920821\tvalid_1's auc: 0.899192\n",
      "[21900]\ttraining's auc: 0.921015\tvalid_1's auc: 0.899209\n",
      "[22200]\ttraining's auc: 0.921186\tvalid_1's auc: 0.899245\n",
      "[22500]\ttraining's auc: 0.921364\tvalid_1's auc: 0.899268\n",
      "[22800]\ttraining's auc: 0.921525\tvalid_1's auc: 0.899275\n",
      "[23100]\ttraining's auc: 0.921683\tvalid_1's auc: 0.8993\n",
      "[23400]\ttraining's auc: 0.921851\tvalid_1's auc: 0.899309\n",
      "[23700]\ttraining's auc: 0.922028\tvalid_1's auc: 0.899313\n",
      "[24000]\ttraining's auc: 0.922195\tvalid_1's auc: 0.899318\n",
      "[24300]\ttraining's auc: 0.92235\tvalid_1's auc: 0.899333\n",
      "[24600]\ttraining's auc: 0.92251\tvalid_1's auc: 0.899368\n",
      "[24900]\ttraining's auc: 0.922691\tvalid_1's auc: 0.899355\n",
      "[25200]\ttraining's auc: 0.922858\tvalid_1's auc: 0.899368\n",
      "[25500]\ttraining's auc: 0.923028\tvalid_1's auc: 0.899375\n",
      "[25800]\ttraining's auc: 0.923197\tvalid_1's auc: 0.899381\n",
      "[26100]\ttraining's auc: 0.923356\tvalid_1's auc: 0.899393\n",
      "[26400]\ttraining's auc: 0.923513\tvalid_1's auc: 0.899394\n",
      "[26700]\ttraining's auc: 0.923669\tvalid_1's auc: 0.899401\n",
      "[27000]\ttraining's auc: 0.923833\tvalid_1's auc: 0.899426\n",
      "[27300]\ttraining's auc: 0.923982\tvalid_1's auc: 0.899428\n",
      "[27600]\ttraining's auc: 0.924129\tvalid_1's auc: 0.89946\n",
      "[27900]\ttraining's auc: 0.924287\tvalid_1's auc: 0.899465\n",
      "[28200]\ttraining's auc: 0.924447\tvalid_1's auc: 0.899474\n",
      "[28500]\ttraining's auc: 0.924609\tvalid_1's auc: 0.899475\n",
      "[28800]\ttraining's auc: 0.924767\tvalid_1's auc: 0.89945\n",
      "Early stopping, best iteration is:\n",
      "[28162]\ttraining's auc: 0.924433\tvalid_1's auc: 0.899493\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[300]\ttraining's auc: 0.76554\tvalid_1's auc: 0.760346\n",
      "[600]\ttraining's auc: 0.805217\tvalid_1's auc: 0.798916\n",
      "[900]\ttraining's auc: 0.824349\tvalid_1's auc: 0.817267\n",
      "[1200]\ttraining's auc: 0.83856\tvalid_1's auc: 0.831073\n",
      "[1500]\ttraining's auc: 0.849241\tvalid_1's auc: 0.841532\n",
      "[1800]\ttraining's auc: 0.856864\tvalid_1's auc: 0.84865\n",
      "[2100]\ttraining's auc: 0.863412\tvalid_1's auc: 0.854863\n",
      "[2400]\ttraining's auc: 0.868655\tvalid_1's auc: 0.859624\n",
      "[2700]\ttraining's auc: 0.87343\tvalid_1's auc: 0.864067\n",
      "[3000]\ttraining's auc: 0.877026\tvalid_1's auc: 0.867164\n",
      "[3300]\ttraining's auc: 0.880458\tvalid_1's auc: 0.870295\n",
      "[3600]\ttraining's auc: 0.883628\tvalid_1's auc: 0.873114\n",
      "[3900]\ttraining's auc: 0.886224\tvalid_1's auc: 0.87535\n",
      "[4200]\ttraining's auc: 0.888446\tvalid_1's auc: 0.877382\n",
      "[4500]\ttraining's auc: 0.89066\tvalid_1's auc: 0.879296\n",
      "[4800]\ttraining's auc: 0.892486\tvalid_1's auc: 0.88079\n",
      "[5100]\ttraining's auc: 0.894119\tvalid_1's auc: 0.882182\n",
      "[5400]\ttraining's auc: 0.895707\tvalid_1's auc: 0.883395\n",
      "[5700]\ttraining's auc: 0.897088\tvalid_1's auc: 0.884564\n",
      "[6000]\ttraining's auc: 0.898408\tvalid_1's auc: 0.885593\n",
      "[6300]\ttraining's auc: 0.899714\tvalid_1's auc: 0.886564\n",
      "[6600]\ttraining's auc: 0.900936\tvalid_1's auc: 0.887608\n",
      "[6900]\ttraining's auc: 0.901937\tvalid_1's auc: 0.888446\n",
      "[7200]\ttraining's auc: 0.902945\tvalid_1's auc: 0.889265\n",
      "[7500]\ttraining's auc: 0.903834\tvalid_1's auc: 0.889948\n",
      "[7800]\ttraining's auc: 0.904683\tvalid_1's auc: 0.890574\n",
      "[8100]\ttraining's auc: 0.905585\tvalid_1's auc: 0.891171\n",
      "[8400]\ttraining's auc: 0.906311\tvalid_1's auc: 0.891687\n",
      "[8700]\ttraining's auc: 0.907043\tvalid_1's auc: 0.892249\n",
      "[9000]\ttraining's auc: 0.907716\tvalid_1's auc: 0.892744\n",
      "[9300]\ttraining's auc: 0.908314\tvalid_1's auc: 0.893168\n",
      "[9600]\ttraining's auc: 0.908934\tvalid_1's auc: 0.893686\n",
      "[9900]\ttraining's auc: 0.909535\tvalid_1's auc: 0.894089\n",
      "[10200]\ttraining's auc: 0.910111\tvalid_1's auc: 0.894472\n",
      "[10500]\ttraining's auc: 0.910542\tvalid_1's auc: 0.894754\n",
      "[10800]\ttraining's auc: 0.91101\tvalid_1's auc: 0.895149\n",
      "[11100]\ttraining's auc: 0.911476\tvalid_1's auc: 0.895459\n",
      "[11400]\ttraining's auc: 0.91193\tvalid_1's auc: 0.895748\n",
      "[11700]\ttraining's auc: 0.912357\tvalid_1's auc: 0.896058\n",
      "[12000]\ttraining's auc: 0.912808\tvalid_1's auc: 0.896327\n",
      "[12300]\ttraining's auc: 0.91318\tvalid_1's auc: 0.896619\n",
      "[12600]\ttraining's auc: 0.913507\tvalid_1's auc: 0.896847\n",
      "[12900]\ttraining's auc: 0.913835\tvalid_1's auc: 0.897064\n",
      "[13200]\ttraining's auc: 0.914133\tvalid_1's auc: 0.897229\n",
      "[13500]\ttraining's auc: 0.914454\tvalid_1's auc: 0.897468\n",
      "[13800]\ttraining's auc: 0.914783\tvalid_1's auc: 0.897688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14100]\ttraining's auc: 0.915085\tvalid_1's auc: 0.897843\n",
      "[14400]\ttraining's auc: 0.915357\tvalid_1's auc: 0.898004\n",
      "[14700]\ttraining's auc: 0.915583\tvalid_1's auc: 0.898145\n",
      "[15000]\ttraining's auc: 0.915868\tvalid_1's auc: 0.898274\n",
      "[15300]\ttraining's auc: 0.916147\tvalid_1's auc: 0.898473\n",
      "[15600]\ttraining's auc: 0.916368\tvalid_1's auc: 0.898552\n",
      "[15900]\ttraining's auc: 0.916608\tvalid_1's auc: 0.898611\n",
      "[16200]\ttraining's auc: 0.916838\tvalid_1's auc: 0.898739\n",
      "[16500]\ttraining's auc: 0.917066\tvalid_1's auc: 0.898843\n",
      "[16800]\ttraining's auc: 0.917311\tvalid_1's auc: 0.898919\n",
      "[17100]\ttraining's auc: 0.917533\tvalid_1's auc: 0.899009\n",
      "[17400]\ttraining's auc: 0.917778\tvalid_1's auc: 0.899074\n",
      "[17700]\ttraining's auc: 0.917991\tvalid_1's auc: 0.899171\n",
      "[18000]\ttraining's auc: 0.918199\tvalid_1's auc: 0.899244\n",
      "[18300]\ttraining's auc: 0.918417\tvalid_1's auc: 0.899285\n",
      "[18600]\ttraining's auc: 0.918618\tvalid_1's auc: 0.899348\n",
      "[18900]\ttraining's auc: 0.918817\tvalid_1's auc: 0.899397\n",
      "[19200]\ttraining's auc: 0.919006\tvalid_1's auc: 0.899461\n",
      "[19500]\ttraining's auc: 0.919203\tvalid_1's auc: 0.89949\n",
      "[19800]\ttraining's auc: 0.9194\tvalid_1's auc: 0.899543\n",
      "[20100]\ttraining's auc: 0.919611\tvalid_1's auc: 0.89962\n",
      "[20400]\ttraining's auc: 0.919791\tvalid_1's auc: 0.899636\n",
      "[20700]\ttraining's auc: 0.91997\tvalid_1's auc: 0.899692\n",
      "[21000]\ttraining's auc: 0.920149\tvalid_1's auc: 0.899712\n",
      "[21300]\ttraining's auc: 0.920326\tvalid_1's auc: 0.899759\n",
      "[21600]\ttraining's auc: 0.920499\tvalid_1's auc: 0.899783\n",
      "[21900]\ttraining's auc: 0.920675\tvalid_1's auc: 0.899784\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "\n",
    "lgbm_params = {\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'min_data_in_leaf': 2881,\n",
    "    'max_depth': 0,\n",
    "    'num_leaves': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'bagging_freq': 3,\n",
    "    #'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.3, 0.9),\n",
    "    'feature_fraction': 0.8453828656355421,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha':  1.1173044727720816,\n",
    "    'reg_lambda': 6.9285776442737514,\n",
    "    'random_state': 42,\n",
    "    'verbosity': -1,\n",
    "    'subsample':0.8421287738494433,\n",
    "    'min_child_weight': 36.93038816860224,\n",
    "    'num_threads': 4,\n",
    "    'max_bin': 483\n",
    "}\n",
    "\n",
    "models = [\n",
    "    ('lgbm', None),\n",
    "    ('lg', SGDClassifier(loss='log', max_iter=5000, tol=1e-7, alpha=0.3)),\n",
    "    ('mlp', MLPClassifier(solver='lbfgs', alpha=0.001, hidden_layer_sizes=(5, 2), random_state=1)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, criterion='entropy')),\n",
    "    ('gnb', GaussianNB()),\n",
    "    ('qda', QuadraticDiscriminantAnalysis(tol=1e-12)),\n",
    "]\n",
    "\n",
    "cv_out = pd.DataFrame(index=train_df.iloc[:,0])\n",
    "test_out = pd.DataFrame(index=test_df.iloc[:,0])\n",
    "\n",
    "# add target to cv_out\n",
    "cv_out['target'] = train_df.iloc[:,1].values\n",
    "\n",
    "for model in models:\n",
    "    name = model[0]\n",
    "    cls = model[1]\n",
    "    print('working on ' + name)\n",
    "    \n",
    "    # k-fold\n",
    "    n_splits = 5\n",
    "    folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    pred_cv = np.zeros(len(X))\n",
    "    pred = np.zeros(len(X_test))\n",
    "    \n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "        print(\"fold: \" + str(fold_n))\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "                        \n",
    "        if name == 'lgbm':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            res = lgb.train(lgbm_params,train_data,num_boost_round=2000000,\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 800)\n",
    "            pred_cv += res.predict(X, num_iteration=res.best_iteration) / n_splits\n",
    "            pred += res.predict(X_test, num_iteration=res.best_iteration) / n_splits\n",
    "        else:\n",
    "            pred_cv += cls.predict_proba(X)[:,1] / n_splits\n",
    "            pred += cls.predict_proba(X_test)[:,1] / n_splits\n",
    "    \n",
    "    print(pred_cv)\n",
    "        \n",
    "    cv_out[name] = pred_cv\n",
    "    test_out[name] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add statistics\n",
    "num = len(models);\n",
    "\n",
    "cv_out['mean'] = cv_out.iloc[:,[1,num]].mean(axis=1)\n",
    "cv_out['min'] = cv_out.iloc[:,[1,num]].min(axis=1)\n",
    "cv_out['max'] = cv_out.iloc[:,[1,num]].max(axis=1)\n",
    "\n",
    "test_out['mean'] = test_out.iloc[:,[0,num-1]].mean(axis=1)\n",
    "test_out['min'] = test_out.iloc[:,[0,num-1]].min(axis=1)\n",
    "test_out['max'] = test_out.iloc[:,[0,num-1]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_out.to_csv('input/train_stack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.to_csv('input/test_stack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
